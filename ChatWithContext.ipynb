{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27921514-5dfa-48a9-a04e-b333fb7958ab",
   "metadata": {},
   "source": [
    "# Chatbot con un LLM - Interfaces de conversación \n",
    "\n",
    "> *Intenta ejecutar este notebook en un Colab o en tu maquina con JupyterLab*\n",
    "\n",
    "En este cuaderno, vamos a crear un chatbot utilizando algunos de los modelos fundacionales de Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db65a0b-bb1c-4a01-9d40-758ade152543",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Los bot conversacionales (chatbot) surgen en los años 60 y simulan la conversación que se lleva a cabo con otra persona. Se trata de programas que utilizan machine learning y procesamiento de lenguaje natural para interpretar las preguntas de los usuarios y responder de forma automatica. \n",
    "Actualmente los chatbot son utilizados en diferentes aplicaciones y dominios de negocio como el servicio al cliente o las ventas para proveer respuestas eficientes a los clientes.  \n",
    "\n",
    "## AWS Bedrock \n",
    "\n",
    "Es un servicio que hace posible acceder por medio de un API modelos fundacionales de Amazon u otros proveedores como AI21 Labs, Anthropic entre otros. \n",
    "\n",
    "## Framework para la construcción de aplicaciones con LLMs LangChain \n",
    "Es un framework para el desarrollo de aplicaciones basadas en LLMs, el cual permite generar soluciones que tengan:  \n",
    "\n",
    "1. Conciencia del contexto: permite conectar el modelo con fuentes de contexto o datos para una mejor interpretación de las solicitudes\n",
    "   \n",
    "3. Razonamiento: Con ayuda de los LLMs permite realizar razonamientos sobre como responder preguntas o que acciones se deben tomar teniendo como base el contexto que se provee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bab3604-a810-4c8b-a228-fa10dfb358c6",
   "metadata": {},
   "source": [
    "### En este laboratorio vamos a construir dos tipos de chatbot\n",
    "\n",
    "1. Chatbot basico - sin contexto\n",
    "\n",
    "2. Chatbot persona (Damos una identidad al chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dabe40-8805-4b91-a36d-799164861a56",
   "metadata": {},
   "source": [
    "### Chatbot basico - sin contexto \n",
    "En nuestro primer ejemplo vamos a utilizar los Chains de Langchain. Los Chains permiten conectar LLMs con otros componentes para crear aplicaciones que requieren flujos mas complejos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9aadce-7e31-4650-975b-83b0044fd4ac",
   "metadata": {},
   "source": [
    "#### Instalación de dependencias\n",
    "Lo primero sera instalar las dependencias necesarias para conectarnos con AWS y crear nuestra aplicación: \n",
    "1. Boto3: SDK de AWS para Python\n",
    "2. Langchain: Framework para desarrollo de aplicaciones basadas en LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a40ab78-5d80-4c93-bfd9-ed40e3179d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (1.28.75)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.75 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from boto3) (1.31.75)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from boto3) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from botocore<1.32.0,>=1.31.75->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from botocore<1.32.0,>=1.31.75->boto3) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.75->boto3) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (0.0.326)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from langchain) (2.0.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from langchain) (0.0.54)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from langchain) (1.26.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from langchain) (1.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rafaelceronespinosa/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3\n",
    "!pip install langchain\n",
    "# !pip install awscli //in case your are going to use google colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd475c1-52c5-44e3-b0df-502639922a3a",
   "metadata": {},
   "source": [
    "#### Importar dependencias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "676cdee8-f434-4228-8000-dfe4529b1aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.memory import ConversationBufferWindowMemory, ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c843ff52-93d1-4f71-90ae-48b75e624c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/config/awscli.ini\n"
     ]
    }
   ],
   "source": [
    "# # en caso que vayas a utilizar Google Colab ejecuta esta celda \n",
    "# monta google drive \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# genera las credenciales \n",
    "!export AWS_SHARED_CREDENTIALS_FILE=/content/drive/MyDrive/config/awscli.ini\n",
    "path = \"/content/drive/My Drive/config/awscli.ini\"\n",
    "os.environ['AWS_SHARED_CREDENTIALS_FILE'] = path\n",
    "print(os.environ['AWS_SHARED_CREDENTIALS_FILE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470bfa3a-9752-44f8-ac1c-846dc59b96e1",
   "metadata": {},
   "source": [
    "#### Inicializar nuestro LLM\n",
    "- model_id: En este caso definimos el modelo que sera utilizado, recordemos que Bedrock nos permite utilizar modelos fundacionales de diversos proveedore\n",
    "\n",
    "- credentials_profile_name: Debes añadir el perfil del AWS-CLI configurado en el notebook initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "776c7828-13d6-480b-b033-6aa4e6a5792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_claude = Bedrock(\n",
    "  model_id=\"anthropic.claude-v2\",\n",
    "  model_kwargs={'max_tokens_to_sample': 200},\n",
    "  credentials_profile_name=\"default\", \n",
    "  region_name=\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf192f-7533-4527-a4f8-c20f3efcc111",
   "metadata": {},
   "source": [
    "En este escenario veremos algunas utilidades de LangChain como:\n",
    "- ConversationBufferWindowMemory facilita el almacenamiento de los mensajes intercambiados con el LLM]\n",
    "- ConversationChain facilita el proceso de comunicación entre un usuario y el LLM\n",
    "\n",
    "* El parametro k representa el tamaño de la ventana de contexto que vamos a tener para comunicarnos con el LLM, en este caso indicamos que se van a mantener en los prompt hasta 5 mensajes intercambiados en el pasado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2da2dd14-e86f-4218-a9b4-b85f1938a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory( k=5, return_messages=True)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm_claude,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b407f6ce-f8fe-43b1-a6ae-ddee46082676",
   "metadata": {},
   "source": [
    "#### Primera prueba \n",
    "Vamos a realizar algunas preguntas a nuestro modelo sobre musica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9550699a-b604-429a-823a-a3738ffe111f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' En la escala de Do mayor, las notas desde Do hasta Mi son:\\n\\nDo, Re, Mi\\n\\nLas notas de la escala de Do mayor son:\\n\\nDo, Re, Mi, Fa, Sol, La, Si, Do\\n\\nEmpezando en Do, las notas hasta llegar a Mi son:\\n\\nDo, Re, Mi'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"En la escala de Do mayor cuales son las notas hasta Mi?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f99df325-ec88-45a5-8ab7-072e694e0b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Después de Mi, las siguientes notas en la escala de Do mayor son:\\n\\nFa, Sol, La, Si, Do\\n\\nAsí que la secuencia completa de notas desde Do hasta el siguiente Do es: \\n\\nDo, Re, Mi, Fa, Sol, La, Si, Do'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"Y despues de Mi?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad49cb80-ae20-4a76-ba64-91a5d1429c1f",
   "metadata": {},
   "source": [
    "En este caso podemos revisar el historial de mensajes intercambiados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7d9403b-a398-4f17-ad80-c266cbb36b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='En la escala de Do mayor cuales son las notas hasta Mi?'),\n",
       "  AIMessage(content=' En la escala de Do mayor, las notas desde Do hasta Mi son:\\n\\nDo, Re, Mi\\n\\nLas notas de la escala de Do mayor son:\\n\\nDo, Re, Mi, Fa, Sol, La, Si, Do\\n\\nEmpezando en Do, las notas hasta llegar a Mi son:\\n\\nDo, Re, Mi'),\n",
       "  HumanMessage(content='Y despues de Mi?'),\n",
       "  AIMessage(content=' Después de Mi, las siguientes notas en la escala de Do mayor son:\\n\\nFa, Sol, La, Si, Do\\n\\nAsí que la secuencia completa de notas desde Do hasta el siguiente Do es: \\n\\nDo, Re, Mi, Fa, Sol, La, Si, Do')]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c36bba-316b-4320-ac72-6abab3b0a8a8",
   "metadata": {},
   "source": [
    "### Chatbot persona \n",
    "Ahora que hemos utilizado los chains vamos a proveer un poco de contexto para nuestro chatbot. \n",
    "En este caso vamos a interactuar con un experto en Café\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14c1f8e7-f140-4169-ad54-46a534612029",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Human: The following is a friendly conversation between a human and an AI.\n",
    "The AI is talkative and provides lots of specific details from its context. If the AI does not know\n",
    "the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "<conversation_history>\n",
    "{history}\n",
    "</conversation_history>\n",
    "\n",
    "Here is the human's next reply:\n",
    "<human_reply>\n",
    "{input}\n",
    "</human_reply>\n",
    "\n",
    "Assistant:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5b3a386-0b54-472c-bbb0-22fbceb03fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are some additional nice name ideas for a new coffee shop in Colombia:\n",
      "\n",
      "- Café de la Sierra - \"Café of the Mountains\", referring to the mountainous terrain where coffee is grown.\n",
      "\n",
      "- Café de la Cosecha - \"Café of the Harvest\", highlighting the fresh-picked coffee beans. \n",
      "\n",
      "- Café del Campo - \"Café of the Countryside\", evoking the rural coffee farms.\n",
      "\n",
      "- Café Rosales - Using a common Colombian surname that sounds pleasant.\n",
      "\n",
      "- Café del Sol - \"Café of the Sun\", connecting to Colombia's sunny weather.\n",
      "\n",
      "- Café Colonial - Evoking Colombia's colonial architecture and history.\n",
      "\n",
      "- Café del Parque - \"Café of the Park\", if it's located near a town square or park.\n",
      "\n",
      "- Café Caribe - Referencing Colombia's Caribbean coastline. \n",
      "\n",
      "- Café Dulce - \"Sweet Café\", emphasizing quality and flavor.\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"You are a coffee expert. Your goal is to give advice to people interested in establishing a coffee venture\")\n",
    "memory.chat_memory.add_ai_message(\"I am a coffee expert and I give advice about how to start coffee ventures\")\n",
    "conversation_persona = ConversationChain(\n",
    "     llm=llm_claude, verbose=True, memory=memory\n",
    ")\n",
    "conversation_persona.prompt = claude_prompt\n",
    "\n",
    "print(conversation.predict(input=\"What will be a nice name for a new coffee shop in Colombia?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f71adbb-f5ef-498e-be58-eae75521bf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv",
   "language": "python",
   "name": "virtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
